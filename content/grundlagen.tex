\section{Grundlagen}

\subsection{Aufbau}
Wie ist ein Neuronales Netzwerk aufgebaut (speziell ein Backprop Network)

Bild mit Layern usw


\subsubsection{Eingangserregung}
Damit ein Neuron des Netzes überhaupt reagieren kann, ist es notwendig, alle eingehenden Werte unter Berücksichtigung ihrer Gewichte miteinander zu kumulieren. Dies geschieht über eine Erregungsfunktion. Es gibt keine Vorschriften für eine solche Erregungsfunktion. Typisch sind jedoch das Skalarprodukt, oder die euklidische Distanz. Diese Erregungsfunktionen $\sigma$ für ein j-tes Neurons mit n Eingängen lauten:

Skalarprodukt:
\begin{equation}
  \sigma_{j} = \sum_{i=1}^{n} w_{ji} x_{i}+w_{j0}
\end{equation} 

euklidische Distanz:
\begin{equation}
  \sigma_{j} = \sum_{i=1}^{n} (w_{ji} - x_{i})^2+w_{j0}^2
\end{equation} 

\subsubsection{Aktivierungsfunktion}
Nachdem der kumulierte Erregungswert $sigma$ mit Hilfe einer Erregungsfunktion berechnet wurde, muss ermittelt werden, wie stark dieser Wert das Neuron aktiviert. Hierfür gibt es ebenfalls diverse Funktionen zu Auswahl.

Eine klassische Schwellwertfunktion ist die Stufenfunktion. Wird ein bestimmter Wert überschritten, wird das Neuron aktiviert und beginnt ebenfalls zu feuern.
\begin{equation}
f(\sigma) = 1 \mbox{ if } \sigma < 0;  \mbox{ else } 0
\end{equation}
% TODO Bild einfügen

Da die Stufenfunktion das Verhalten eines Neurons sehr gut abbildet, allerdings nicht stetig und damit nicht vollständig differenzierbar ist, wurde sie durch die Sigmoidfunktion angenähert. Diese erhält den Schwellwertcharakter der Stufenfunktion, steigt aber flacher an und umgeht so die Unstetigkeit.
Sigmoidfunktion:
\begin{equation}
f(\sigma) = \frac{1}{1+e^{-\sigma}}
\end{equation}
% TODO Bild einfügen

Ein weiterer Vorteil der Sigmoidfunktion ist die sehr einfache Ableitung, die eine effiziente Implementierung ermöglicht.
\begin{equation}
f'(\sigma) = f(\sigma)\cdot (1- f(\sigma))
\end{equation}

Soll das Neuron nur innerhalb eines bestimmten Bereichs aktiviert werden, eignet sich eine Glockenfunktion. Sie approximiert eine Fensterfunktion, ist aber ebenfalls stetig.
\begin{equation}
f(\sigma) = e^{-\sigma^2}
\end{equation}
% TODO Bild einfügen



\subsection{Feedforward Berechnung}
Nachdem nun die Eigenschaften eines einzelnen Neurons definiert wurden, ist es möglich, den gesamten Output eines ganzen Netzes zu berechnen.  Es wird jeweils der Input der vorherigen Schicht kumuliert und das Ergebnis der Aktivierungsfunktion an die nachfolgende Schicht weitergegeben. Für die nachfolgende Formel wurde das Skalarprodukt, sowie ein Hidden-Layer zugrunde gelegt. Bei mehr Hidden-Layern müsste die Funktion diese ebenso als Summe verschachteln.
\begin{equation}
o_{k}(\vec{x})=f\left( \sum_{j=1}^{n_{hidden}} w_{kj} f\left(\sum_{i=1}^{n_{input}} w_{ji}x_{i}+w_{j0} \right)+w_{k0} \right)
\end{equation}
Um die Vollständige Systemantwort zu erhalten, muss diese Funktion für jedes Neuron des Output-Layers berechnet werden.

\subsection{Training}

Damit ein neuronales Netz eine adäquate Systemantwort generieren kann, ist es notwendig dieses zu trainieren. In der Natur geschieht dies, indem die einzelnen Verbindungen zwischen zwei Neuronen dicker werden, oder sogar neue entstehen. Zumindest das Dickenwachstum lässt sich im mathematischen Modell durch die Modifikation der Gewichte nachbilden. Wichtige Neuronen werden ungefiltert, oder sogar verstärkt in den Erregungswert einfließen, unwichtige Neuronen werden gedämpft.

Um das neuronale Netz zu trainieren, muss ein Teil der Daten manuell bearbeitet werden. Die eine Hälfte dieses Datensatzes wird als zum Training des Netzes eingesetzt, der Andere zur Verifikation der Arbeitsweise.
 
Beim Training des Netzes wird die generierte Systemantwort o des Output-Neurons k mit dem gewünschten Ergebnis t verglichen und die Differenz $t_k - o_k$ berechnet. Da nur der absolute Abstand wichtig ist, müsste eigentlich des Betrag dieser Differenz berechnet werden. Da die Betragsfunktion allerdings nicht stetig und dadurch nur partiell ableitbar ist, wird hier das Quadrat genommen. Der Faktor $\frac{1}{2}$ existiert nur, damit die Ableitung ohne einen Faktor auskommt und leichter zu verrechnen ist.
\begin{equation}
E = \frac{1}{2} \sum_{k=1}^{c}(t_{k}-o_{k})^2
\end{equation}

Diese Fehlerfunktion $E$ gilt es nun zu minimieren.

\subsubsection{Das Gradientenabstiegsverfahren}
Eine Möglichkeit der Minimierung des Fehlers ist das Gradientenabstiegsverfahren. Hierbei wird die Fehlerfunktion nach dem Gewicht, dem einzig veränderbaren Parameter, abgeleitet, um die Richtung des Minimums zu ermitteln. leider ist es so nicht möglich, den Abstand zum Minimum zu ermitteln. Deswegen wird mit der Lernrate $\eta$ eine Schrittweite festgelegt, mit der sich in Richtung dieses Minimums bewegt wird.
\begin{equation}
\Delta w_{pq}=-\eta \frac{\delta E}{\delta w_{pq}}
\end{equation}

Diese Formel gilt es nun für die einzelnen Schichten anzuwenden. Hierbei muss eine Fallunterscheidung vorgenommen werden, ob es sich um ein Neuron des Output-Layers handelt, oder eines des Hidden-Layers, da die Neuronen des Output-Layers keine nachfolgende Schicht mehr bedienen und ihr Output ungefiltert als Systemantwort an die Außenwelt gelangt.

Berechnung der Änderung der Gewichte für das \emph{Output-Layer:}

Die Fehlerfunktion $E$ wird durch Anwendung der Kettenregel erweitert. So wird $E$ nicht direkt nach $w$ abgeleitet, sondern nach der Erregungsfunktion $\sigma$. Diese wird dann gesondert nach $w$ abgeleitet.
\begin{equation}
\frac{\delta E}{\delta w_{pq}} = \frac{\delta E}{\delta \sigma_{k}} \frac{\delta \sigma_{k}}{\delta w_{kj}}
\label{eqn:output-erw}
\end{equation}

Diese Erweiterung ermöglicht es, die einzelnen Faktoren separat zu betrachten. Die Fehlerfunktion $E$ wird nun wieder mittels Kettenregel erweitert. So wird diese erst nach dem Faktor $o$ (Ergebnis der Funktion $o()$) abgeleitet und die Funktion $o()$ nach $\sigma$.
\begin{equation}
\frac{\delta E}{\delta \sigma_{k}} = \frac{\delta E}{\delta o_{k}} \frac{\delta o_k}{\delta \sigma_k} = -(t_k - o_k) f'(\sigma_k)
\end{equation}
Wie man sieht, wird die Ableitung dadurch enorm erleichtert. Der erste Teil ist die Differenz zwischen Ist- und Sollwert, der zweite Teil die Ableitung der Aktivierungsfunktion. Ist diese die Sigmoidfunktion, so lautet die Ableitung $f'(\sigma)=f(\sigma)\cdot (1-f(\sigma))$.

Der zweite Teil der Ableitung \ref{eqn:output-erw} ist noch einfacher. Er ist der Output des Neurons aus dem Hidden-Layer, der ja bereits bei der Berechnung des allgemeinen Outputs berechnet wurde
\begin{equation}
\frac{\delta\sigma_k}{\delta w_{kj}}=y_j
\end{equation}

In die ursprüngliche Gleichung eingesetzt, ergibt sich folgende Formel:
\begin{equation}
\Delta w_{kj} = \eta (t_k - o_k) f'(\sigma_k)y_j
\end{equation}

Der mittlere Teil wird in der Regel extrahiert, da er für alle Neuronen gleich berechnet wird und so die Implementierung erleichtert.
\begin{equation}
\delta_k = (t_k - o_k) f'(\sigma_k)
\end{equation}

So lautet dann die endgültige Formel zur Berechnung der Änderung des Gewichts der Verbindung zwischen dem Neuron $j$ des Hidden-Layer und dem Neuron $k$ des Output-Layer:
\begin{equation}
\Delta w_{kj} = \eta\cdot \delta_k \cdot y_j
\end{equation}

Berechnung der Änderung der Gewichte für das \emph{Hidden-Layer:}

Die Berechnung für ein Neuron des Hidden-Layer ist ein wenig komplexer, da hier die eigentliche Backpropagation stattfindet und der Fehler der nachfolgenden Schicht (hier das Output-Layer) berücksichtigt wird. Auch hier wird die Ableitung durch den Einsatz der Kettenregel vereinfacht.
\begin{equation}
\frac{\delta E}{\delta w_{ji}} = \frac{\delta E}{\delta y_j} \frac{\delta y_j}{\delta\sigma_j}\frac{\delta\sigma_j}{\delta w_{ji}}
\end{equation}

Die einzelnen Terme werden analog zum Vorgehen bei dem Output-Layer separat abgeleitet und in die alte Formel eingesetzt. Hier sieht man, dass die Formel der des Output-Layers sehr ähnlich sieht. Die Änderung des Gewichts berücksichtigt allerdings den Fehler aller mit dem Neuron verbundenen Output-Neuronen.
\begin{equation}
\Delta w_{ji} = \eta \cdot \left(\sum_{k=1}^{c}(t_k-o_k)\cdot f'(\sigma_k)\cdot w_{kj}\right) \cdot f'(\sigma_j) \cdot x_i
\end{equation}

Auch hier wird wieder der mittlere Teil herausgezogen und in einem separaten Parameter zusammengefasst.
\begin{equation}
\mbox{mit } \delta_k = (t_k-o_k)\cdot f'(\sigma_k)
\end{equation}

Die endgültige Formel für ein Neuron des Hidden-Layer lautet:
\begin{equation}
\Delta w_{ji}=\eta \cdot \left(\sum_{k=1}^{c} \delta_k w_{kj}\right)\cdot f'(\sigma_j)\cdot x_i
\end{equation}
Sie beinhaltet den Fehler der verbundenen Output-Neuronen, sowie das Gewicht der Verbindung zu ihnen, die Ableitung der eigenen Aktivierungsfunktion, sowie den Input des Neurons aus der vorherigen Schicht. Diese Funktion muss also für jede einzelnen eingehende Verbindung zu diesem Neuron berechnet werden. die gestaltet sich allerdings äußerst einfach, da einmal berechnet, alle Faktoren bis auf $x_i$ für diesen Lernschritt gleich bleiben.

Nachdem nun die Änderung der Gewichte berechnet wurde, wird nun das alte Gewicht angepasst und ein weiterer Lernschritt kann erfolgen.
\begin{equation}
w_{pq, neu}=w_{pq, alt}+\Delta w_{pq}
\end{equation}




\subsection{Ausführung}
welche Schritte aus dem Training werden wiederholt
(Ausführung ist ein unglücklicher Name)